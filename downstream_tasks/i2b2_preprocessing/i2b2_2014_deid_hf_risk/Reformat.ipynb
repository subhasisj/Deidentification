{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, xml.etree.ElementTree as ET, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CDATA = \"<TEXT><![CDATA[\"\n",
    "END_CDATA   = \"]]></TEXT>\"\n",
    "\n",
    "TAGS        = ['MEDICATION', 'OBSEE', 'SMOKER', 'HYPERTENSION', 'PHI', 'FAMILY_HIST']\n",
    "\n",
    "def read_xml_file(xml_path, PHI_tag_type='ALL_CHILDREN', match_text=True):\n",
    "    with open(xml_path, mode='r') as f:\n",
    "        lines = f.readlines()\n",
    "        text, in_text = [], False\n",
    "        for i, l in enumerate(lines):\n",
    "            if START_CDATA in l:\n",
    "                text.append(list(l[l.find(START_CDATA) + len(START_CDATA):]))\n",
    "                in_text = True\n",
    "            elif END_CDATA in l:\n",
    "                text.append(list(l[:l.find(END_CDATA)]))\n",
    "                break\n",
    "            elif in_text:\n",
    "                if xml_path.endswith('180-03.xml') and '0808' in l and 'Effingham' in l:\n",
    "                    print(\"Adjusting known error\")\n",
    "                    l = l[:9] + ' ' * 4 + l[9:]\n",
    "#                 elif xml_path.endswith('188-05.xml') and 'Johnson & Johnson' in l:\n",
    "#                     print(\"Adjusting known error\")\n",
    "#                     l = l.replace('&', 'and')\n",
    "                text.append(list(l))\n",
    "        \n",
    "    pos_transformer = {}\n",
    "    \n",
    "    linear_pos = 1\n",
    "    for line, sentence in enumerate(text):\n",
    "        for char_pos, char in enumerate(sentence):\n",
    "            pos_transformer[linear_pos] = (line, char_pos)\n",
    "            linear_pos += 1\n",
    "        \n",
    "    xml_parsed = ET.parse(xml_path)\n",
    "    tag_containers = xml_parsed.findall('TAGS')\n",
    "    assert len(tag_containers) == 1, \"Found multiple tag sets!\"\n",
    "    tag_container = tag_containers[0]\n",
    "    \n",
    "    PHI_tags = tag_container.getchildren() if PHI_tag_type == 'ALL_CHILDREN' else tag_container.findall('PHI')\n",
    "    PHI_labels = [['O'] * len(sentence) for sentence in text]\n",
    "    for PHI_tag in PHI_tags:\n",
    "        base_label = PHI_tag.attrib['TYPE']\n",
    "        start_pos, end_pos, PHI_text = PHI_tag.attrib['start'], PHI_tag.attrib['end'], PHI_tag.attrib['text']\n",
    "        start_pos, end_pos = int(start_pos)+1, int(end_pos)\n",
    "        PHI_text = ' '.join(PHI_text.split())\n",
    "#         if PHI_text == \"0808 O’neil’s Court\":\n",
    "#             print(\"Adjusting known error\")\n",
    "#             end_pos -= 4\n",
    "        if PHI_text == 'Johnson and Johnson' and xml_path.endswith('188-05.xml'):\n",
    "            print(\"Adjusting known error\")\n",
    "            PHI_text = 'Johnson & Johnson'\n",
    "        \n",
    "\n",
    "        (start_line, start_char), (end_line, end_char) = pos_transformer[start_pos], pos_transformer[end_pos]\n",
    "            \n",
    "        obs_text = []\n",
    "        for line in range(start_line, end_line+1):\n",
    "            t = text[line]\n",
    "            s = start_char if line == start_line else 0\n",
    "            e = end_char if line == end_line else len(t)\n",
    "            obs_text.append(''.join(t[s:e+1]).strip())\n",
    "        obs_text = ' '.join(obs_text)\n",
    "        obs_text = ' '.join(obs_text.split())\n",
    "              \n",
    "        if match_text: assert obs_text == PHI_text, (\n",
    "            (\"Texts don't match! %s v %s\" % (PHI_text, obs_text)) + '\\n' + str((\n",
    "                start_pos, end_pos, line, s, e, t, xml_path\n",
    "            ))\n",
    "        )\n",
    "        \n",
    "        PHI_labels[end_line][end_char]     = 'I-%s' % base_label\n",
    "        PHI_labels[start_line][start_char] = 'B-%s' % base_label\n",
    "        \n",
    "        for line in range(start_line, end_line+1):\n",
    "            t = text[line]\n",
    "            s = start_char+1 if line == start_line else 0\n",
    "            e = end_char-1 if line == end_line else len(t)-1\n",
    "            for i in range(s, e+1): PHI_labels[line][i] = 'I-%s' % base_label\n",
    "\n",
    "    return text, PHI_labels\n",
    "    \n",
    "def merge_into_words(text_by_char, all_labels_by_char):\n",
    "    assert len(text_by_char) == len(all_labels_by_char), \"Incorrect # of sentences!\"\n",
    "    \n",
    "    N = len(text_by_char)\n",
    "    \n",
    "    text_by_word, all_labels_by_word = [], []\n",
    "    \n",
    "    for sentence_num in range(N):\n",
    "        sentence_by_char = text_by_char[sentence_num]\n",
    "        labels_by_char   = all_labels_by_char[sentence_num]\n",
    "        \n",
    "        assert len(sentence_by_char) == len(labels_by_char), \"Incorrect # of chars in sentence!\"\n",
    "        S = len(sentence_by_char)\n",
    "        \n",
    "        if labels_by_char == (['O'] * len(sentence_by_char)):\n",
    "            sentence_by_word = ''.join(sentence_by_char).split()\n",
    "            labels_by_word   = ['O'] * len(sentence_by_word)\n",
    "        else: \n",
    "            sentence_by_word, labels_by_word = [], []\n",
    "            text_chunks, labels_chunks = [], []\n",
    "            s = 0\n",
    "            for i in range(S):\n",
    "                if i == S-1:\n",
    "                    text_chunks.append(sentence_by_char[s:])\n",
    "                    labels_chunks.append(labels_by_char[s:])\n",
    "                elif labels_by_char[i] == 'O': continue\n",
    "                else:\n",
    "                    if i > 0 and labels_by_char[i-1] == 'O':\n",
    "                        text_chunks.append(sentence_by_char[s:i])\n",
    "                        labels_chunks.append(labels_by_char[s:i])\n",
    "                        s = i\n",
    "                    if labels_by_char[i+1] == 'O' or labels_by_char[i+1][2:] != labels_by_char[i][2:]:\n",
    "                        text_chunks.append(sentence_by_char[s:i+1])\n",
    "                        labels_chunks.append(labels_by_char[s:i+1])\n",
    "                        s = i+1\n",
    "                \n",
    "            for text_chunk, labels_chunk in zip(text_chunks, labels_chunks):\n",
    "                assert len(text_chunk) == len(labels_chunk), \"Bad Chunking (len)\"\n",
    "                assert len(text_chunk) > 0, \"Bad chunking (len 0)\" + str(text_chunks) + str(labels_chunks)\n",
    "                \n",
    "                labels_set = set(labels_chunk)\n",
    "                assert labels_set == set(['O']) or (len(labels_set) <= 3 and 'O' not in labels_set), (\n",
    "                    (\"Bad chunking (contents) %s\" % ', '.join(labels_set))+ str(text_chunks) + str(labels_chunks)\n",
    "                )\n",
    "                \n",
    "                text_chunk_by_word = ''.join(text_chunk).split()\n",
    "                W = len(text_chunk_by_word)\n",
    "                if W == 0: \n",
    "#                     assert labels_set == set(['O']), \"0-word chunking and non-0 label!\" + str(\n",
    "#                         text_chunks) + str(labels_chunks\n",
    "#                     )\n",
    "                    continue\n",
    "                \n",
    "                if labels_chunk[0] == 'O': labels_chunk_by_word = ['O'] * W\n",
    "                elif W == 1:               labels_chunk_by_word = [labels_chunk[0]]\n",
    "                elif W == 2:               labels_chunk_by_word = [labels_chunk[0], labels_chunk[-1]]\n",
    "                else:                      labels_chunk_by_word = [\n",
    "                        labels_chunk[0]\n",
    "                    ] + [labels_chunk[1]] * (W - 2) + [\n",
    "                        labels_chunk[-1]\n",
    "                    ]\n",
    "                    \n",
    "                sentence_by_word.extend(text_chunk_by_word)\n",
    "                labels_by_word.extend(labels_chunk_by_word)\n",
    "\n",
    "        assert len(sentence_by_word) == len(labels_by_word), \"Incorrect # of words in sentence!\"    \n",
    "        \n",
    "        if len(sentence_by_word) == 0: continue\n",
    "            \n",
    "        text_by_word.append(sentence_by_word)\n",
    "        all_labels_by_word.append(labels_by_word)\n",
    "    return text_by_word, all_labels_by_word\n",
    "\n",
    "def reprocess_PHI_labels(folders, base_path='.', PHI_tag_type='PHI', match_text=True, dev_set_size=None):\n",
    "    all_texts_by_patient, all_labels_by_patient = {}, {}\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_dir = os.path.join(base_path, folder)\n",
    "        xml_filenames = [x for x in os.listdir(folder_dir) if x.endswith('xml')]\n",
    "        for xml_filename in xml_filenames:\n",
    "            patient_num = int(xml_filename[:3])\n",
    "            xml_filepath = os.path.join(folder_dir, xml_filename)\n",
    "            \n",
    "            text_by_char, labels_by_char = read_xml_file(\n",
    "                xml_filepath,\n",
    "                PHI_tag_type=PHI_tag_type,\n",
    "                match_text=match_text\n",
    "            )\n",
    "            text_by_word, labels_by_word = merge_into_words(text_by_char, labels_by_char)\n",
    "            \n",
    "            if patient_num not in all_texts_by_patient:\n",
    "                all_texts_by_patient[patient_num] = []\n",
    "                all_labels_by_patient[patient_num] = []\n",
    "            \n",
    "            all_texts_by_patient[patient_num].extend(text_by_word)\n",
    "            all_labels_by_patient[patient_num].extend(labels_by_word)\n",
    "            \n",
    "    patients = set(all_texts_by_patient.keys())\n",
    "    \n",
    "    if dev_set_size is None: train_patients, dev_patients = list(patients), []\n",
    "    else:\n",
    "        N_train = int(len(patients) * (1-dev_set_size))\n",
    "        patients_random = np.random.permutation(list(patients))\n",
    "        train_patients = list(patients_random[:N_train])\n",
    "        dev_patients   = list(patients_random[N_train:])\n",
    "    \n",
    "    train_texts, train_labels = [], []\n",
    "    dev_texts, dev_labels = [], []\n",
    "    \n",
    "    for patient_num in train_patients:\n",
    "        train_texts.extend(all_texts_by_patient[patient_num])\n",
    "        train_labels.extend(all_labels_by_patient[patient_num])\n",
    "\n",
    "    for patient_num in dev_patients:\n",
    "        dev_texts.extend(all_texts_by_patient[patient_num])\n",
    "        dev_labels.extend(all_labels_by_patient[patient_num])\n",
    "\n",
    "\n",
    "    train_out_text_by_sentence = []\n",
    "    for text, labels in zip(train_texts, train_labels):\n",
    "        train_out_text_by_sentence.append('\\n'.join('%s %s' % x for x in zip(text, labels)))\n",
    "    dev_out_text_by_sentence = []\n",
    "    for text, labels in zip(dev_texts, dev_labels):\n",
    "        dev_out_text_by_sentence.append('\\n'.join('%s %s' % x for x in zip(text, labels)))\n",
    "\n",
    "    return '\\n\\n'.join(train_out_text_by_sentence), '\\n\\n'.join(dev_out_text_by_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subha\\AppData\\Local\\Temp\\ipykernel_9020\\1517411791.py:39: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  PHI_tags = tag_container.getchildren() if PHI_tag_type == 'ALL_CHILDREN' else tag_container.findall('PHI')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting known error\n"
     ]
    }
   ],
   "source": [
    "final_train_text, final_dev_text = reprocess_PHI_labels(\n",
    "    ['../../../training-PHI-Gold-Set1/', '../../../training-PHI-Gold-Set2/'], PHI_tag_type='ALL_CHILDREN',\n",
    "    dev_set_size=0.1, match_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subha\\AppData\\Local\\Temp\\ipykernel_9020\\1517411791.py:39: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  PHI_tags = tag_container.getchildren() if PHI_tag_type == 'ALL_CHILDREN' else tag_container.findall('PHI')\n"
     ]
    }
   ],
   "source": [
    "test_text, _ = reprocess_PHI_labels(\n",
    "    ['../../../testing-PHI-Gold-fixed'], PHI_tag_type='ALL_CHILDREN', match_text=False, dev_set_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record O\n",
      "date: O\n",
      "2087-04-06 B-DATE\n",
      "\n",
      "PROBLEMS O\n",
      "\n",
      "Diabetes O\n",
      "mellitus O\n",
      "\n",
      "Hypertension O\n",
      "\n",
      "Psoriasis O\n",
      "\n",
      "Hysterectomy O\n",
      "due O\n",
      "to O\n",
      "bleeding O\n",
      "\n",
      "Gastrectomy O\n",
      "partial, O\n",
      "PUD O\n",
      "2061 B-DATE\n",
      "\n",
      "PVD: O\n",
      "iliac O\n",
      "disease, O\n",
      "compensated O\n",
      "distally O\n",
      "\n",
      "MEDICATIONS O\n",
      "\n",
      "one O\n",
      "touch O\n",
      "test O\n",
      "strips O\n",
      "\n",
      "ATENOLOL O\n",
      "50MG O\n",
      "1 O\n",
      "Tablet(s) O\n",
      "PO O\n",
      "QD O\n",
      "90 O\n",
      "day(s) O\n",
      "\n",
      "GLYBURIDE O\n",
      "5MG O\n",
      "0.5 O\n",
      "Tablet(s) O\n",
      "PO O\n",
      "QD O\n",
      "\n",
      "63 B-AGE\n",
      "yo O\n",
      "returns O\n",
      "for O\n",
      "med O\n",
      "refills O\n",
      "after O\n",
      "1 O\n",
      "1/2 O\n",
      "yr O\n",
      "hiatus. O\n",
      "Has O\n",
      "not O\n",
      "kept O\n",
      "up O\n",
      "with O\n",
      "rout\n"
     ]
    }
   ],
   "source": [
    "print(final_train_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record O\n",
      "date: O\n",
      "2121-05-09 B-DATE\n",
      "\n",
      "BCH B-HOSPITAL\n",
      "EMERGENCY O\n",
      "DEPT O\n",
      "VISIT O\n",
      "\n",
      "HOLCOMB,DENNIS B-PATIENT\n",
      "833-12-06-0 B-MEDICALRECORD\n",
      "VISIT O\n",
      "DATE: O\n",
      "05/09/21 B-DATE\n",
      "\n",
      "This O\n",
      "patient O\n",
      "was O\n",
      "seen, O\n",
      "interviewed O\n",
      "and O\n",
      "examined O\n",
      "by O\n",
      "myself O\n",
      "as O\n",
      "well O\n",
      "\n",
      "as O\n",
      "Dr. O\n",
      "Petty B-DOCTOR\n",
      "whose O\n",
      "I O\n",
      "have O\n",
      "reviewed O\n",
      "and O\n",
      "whose O\n",
      "findings O\n",
      "I O\n",
      "have O\n",
      "\n",
      "confirmed. O\n",
      "\n",
      "HISTORY O\n",
      "OF O\n",
      "PRESENTING O\n",
      "COMPLAINT: \n"
     ]
    }
   ],
   "source": [
    "print(final_dev_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record O\n",
      "date: O\n",
      "2069-04-07 B-DATE\n",
      "\n",
      "Mr. O\n",
      "Villegas B-PATIENT\n",
      "is O\n",
      "seen O\n",
      "today. O\n",
      "I O\n",
      "have O\n",
      "not O\n",
      "seen O\n",
      "him O\n",
      "since O\n",
      "November B-DATE\n",
      ". O\n",
      "\n",
      "About O\n",
      "three O\n",
      "weeks O\n",
      "ago O\n",
      "he O\n",
      "stopped O\n",
      "his O\n",
      "Prednisone O\n",
      "on O\n",
      "his O\n",
      "own O\n",
      "because O\n",
      "\n",
      "he O\n",
      "was O\n",
      "gaining O\n",
      "weight. O\n",
      "He O\n",
      "does O\n",
      "feel O\n",
      "that O\n",
      "his O\n",
      "shoulders O\n",
      "are O\n",
      "\n",
      "definitely O\n",
      "improved. O\n",
      "It O\n",
      "is O\n",
      "unclear O\n",
      "what O\n",
      "he O\n",
      "is O\n",
      "actually O\n",
      "taking, O\n",
      "bu\n"
     ]
    }
   ],
   "source": [
    "print(test_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for s in final_train_text, final_dev_text, test_text:\n",
    "    for line in s.split('\\n'):\n",
    "        if line == '': continue\n",
    "        label = line.split()[-1]\n",
    "        assert label == 'O' or label.startswith('B-') or label.startswith('I-'), \"label wrong! %s\" % label\n",
    "        if label not in labels: labels[label] = 1\n",
    "        else: labels[label] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 777074,\n",
       " 'B-DATE': 12451,\n",
       " 'B-AGE': 1995,\n",
       " 'B-DOCTOR': 4786,\n",
       " 'B-HOSPITAL': 2306,\n",
       " 'B-PATIENT': 2192,\n",
       " 'B-MEDICALRECORD': 1032,\n",
       " 'I-DOCTOR': 3471,\n",
       " 'I-PATIENT': 1191,\n",
       " 'B-IDNUM': 456,\n",
       " 'I-HOSPITAL': 1827,\n",
       " 'B-STREET': 349,\n",
       " 'I-STREET': 711,\n",
       " 'B-CITY': 651,\n",
       " 'B-STATE': 501,\n",
       " 'B-ZIP': 349,\n",
       " 'B-PHONE': 524,\n",
       " 'I-DATE': 1373,\n",
       " 'B-ORGANIZATION': 205,\n",
       " 'I-ORGANIZATION': 168,\n",
       " 'B-PROFESSION': 413,\n",
       " 'I-PROFESSION': 346,\n",
       " 'I-PHONE': 100,\n",
       " 'B-USERNAME': 356,\n",
       " 'I-AGE': 10,\n",
       " 'I-CITY': 171,\n",
       " 'I-IDNUM': 30,\n",
       " 'B-COUNTRY': 183,\n",
       " 'I-MEDICALRECORD': 47,\n",
       " 'I-COUNTRY': 21,\n",
       " 'B-BIOID': 1,\n",
       " 'B-LOCATION-OTHER': 17,\n",
       " 'I-LOCATION-OTHER': 15,\n",
       " 'B-EMAIL': 5,\n",
       " 'B-FAX': 10,\n",
       " 'I-FAX': 2,\n",
       " 'B-DEVICE': 15,\n",
       " 'B-HEALTHPLAN': 1,\n",
       " 'I-HEALTHPLAN': 1,\n",
       " 'I-STATE': 18,\n",
       " 'B-URL': 2,\n",
       " 'I-URL': 4,\n",
       " 'I-DEVICE': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../../../processed/label.txt\", \"w\")\n",
    "for label in reversed(sorted(labels)):\n",
    "    f.write(label+\"\\n\")\n",
    "f.close()\n",
    "\n",
    "\n",
    "with open('../../../processed/train.txt', mode='w') as f:\n",
    "    f.write(final_train_text)\n",
    "with open('../../../processed/dev.txt', mode='w') as f:\n",
    "    f.write(final_dev_text)\n",
    "with open('../../../processed/test.txt', mode='w') as f:\n",
    "    f.write(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('all-purpose-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "988aea983bc49b4de6555a9151e99301026502c3eb4adf0dc68b340a087613cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
